{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train_final.csv',index_col=False)\n",
    "labels=df_train[['784']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  774  775  776  777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1  255  255  255  255  255  255  255  255  255  255  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(df_train.columns[[784]],axis=1,inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1212)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels=np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "cat=to_categorical(labels,num_classes=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(cat[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  774  775  776  777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1  255  255  255  255  255  255  255  255  255  255  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(77021):\n",
    "    l.append(np.array(df_train[i:i+1]).reshape(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77021\n"
     ]
    }
   ],
   "source": [
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1 , 28, 28), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77021/77021 [==============================] - 210s 3ms/step - loss: 0.5525 - acc: 0.8641\n",
      "Epoch 2/200\n",
      "77021/77021 [==============================] - 219s 3ms/step - loss: 0.1765 - acc: 0.9451\n",
      "Epoch 3/200\n",
      "77021/77021 [==============================] - 229s 3ms/step - loss: 0.1342 - acc: 0.9575\n",
      "Epoch 4/200\n",
      "77021/77021 [==============================] - 230s 3ms/step - loss: 0.1143 - acc: 0.9640\n",
      "Epoch 5/200\n",
      "77021/77021 [==============================] - 233s 3ms/step - loss: 0.1038 - acc: 0.9663\n",
      "Epoch 6/200\n",
      "77021/77021 [==============================] - 233s 3ms/step - loss: 0.0930 - acc: 0.9702\n",
      "Epoch 7/200\n",
      "77021/77021 [==============================] - 232s 3ms/step - loss: 0.0876 - acc: 0.9722\n",
      "Epoch 8/200\n",
      "77021/77021 [==============================] - 233s 3ms/step - loss: 0.0835 - acc: 0.9734\n",
      "Epoch 9/200\n",
      "77021/77021 [==============================] - 233s 3ms/step - loss: 0.0769 - acc: 0.9755\n",
      "Epoch 10/200\n",
      "77021/77021 [==============================] - 213s 3ms/step - loss: 0.0751 - acc: 0.9756\n",
      "Epoch 11/200\n",
      "77021/77021 [==============================] - 215s 3ms/step - loss: 0.0716 - acc: 0.9779\n",
      "Epoch 12/200\n",
      "77021/77021 [==============================] - 213s 3ms/step - loss: 0.0706 - acc: 0.9779 1s - loss:\n",
      "Epoch 13/200\n",
      "77021/77021 [==============================] - 212s 3ms/step - loss: 0.0670 - acc: 0.9791\n",
      "Epoch 14/200\n",
      "77021/77021 [==============================] - 213s 3ms/step - loss: 0.0671 - acc: 0.9793\n",
      "Epoch 15/200\n",
      "77021/77021 [==============================] - 213s 3ms/step - loss: 0.0647 - acc: 0.9799\n",
      "Epoch 16/200\n",
      "77021/77021 [==============================] - 211s 3ms/step - loss: 0.0622 - acc: 0.9800\n",
      "Epoch 17/200\n",
      "77021/77021 [==============================] - 214s 3ms/step - loss: 0.0606 - acc: 0.9807\n",
      "Epoch 18/200\n",
      "77021/77021 [==============================] - 213s 3ms/step - loss: 0.0613 - acc: 0.9813\n",
      "Epoch 19/200\n",
      "77021/77021 [==============================] - 212s 3ms/step - loss: 0.0592 - acc: 0.9816\n",
      "Epoch 20/200\n",
      "77021/77021 [==============================] - 214s 3ms/step - loss: 0.0615 - acc: 0.9806\n",
      "Epoch 21/200\n",
      "77021/77021 [==============================] - 214s 3ms/step - loss: 0.0594 - acc: 0.9822\n",
      "Epoch 22/200\n",
      "77021/77021 [==============================] - 214s 3ms/step - loss: 0.0572 - acc: 0.9822\n",
      "Epoch 23/200\n",
      "77021/77021 [==============================] - 216s 3ms/step - loss: 0.0556 - acc: 0.9826\n",
      "Epoch 24/200\n",
      "77021/77021 [==============================] - 219s 3ms/step - loss: 0.0556 - acc: 0.9827\n",
      "Epoch 25/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0542 - acc: 0.9834\n",
      "Epoch 26/200\n",
      "77021/77021 [==============================] - 233s 3ms/step - loss: 0.0555 - acc: 0.9839\n",
      "Epoch 27/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0524 - acc: 0.9838\n",
      "Epoch 28/200\n",
      "77021/77021 [==============================] - 234s 3ms/step - loss: 0.0558 - acc: 0.9839\n",
      "Epoch 29/200\n",
      "77021/77021 [==============================] - 238s 3ms/step - loss: 0.0563 - acc: 0.9834\n",
      "Epoch 30/200\n",
      "77021/77021 [==============================] - 239s 3ms/step - loss: 0.0531 - acc: 0.9840\n",
      "Epoch 31/200\n",
      "77021/77021 [==============================] - 238s 3ms/step - loss: 0.0539 - acc: 0.9842\n",
      "Epoch 32/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0512 - acc: 0.9841\n",
      "Epoch 33/200\n",
      "77021/77021 [==============================] - 238s 3ms/step - loss: 0.0529 - acc: 0.9843\n",
      "Epoch 34/200\n",
      "77021/77021 [==============================] - 239s 3ms/step - loss: 0.0509 - acc: 0.9847\n",
      "Epoch 35/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.0506 - acc: 0.9849\n",
      "Epoch 36/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.0512 - acc: 0.9851\n",
      "Epoch 37/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0503 - acc: 0.9852\n",
      "Epoch 38/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0503 - acc: 0.9854\n",
      "Epoch 39/200\n",
      "77021/77021 [==============================] - 243s 3ms/step - loss: 0.0515 - acc: 0.9848\n",
      "Epoch 40/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.0502 - acc: 0.9850\n",
      "Epoch 41/200\n",
      "77021/77021 [==============================] - 235s 3ms/step - loss: 0.0514 - acc: 0.9851\n",
      "Epoch 42/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0493 - acc: 0.9855\n",
      "Epoch 43/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0488 - acc: 0.9860\n",
      "Epoch 44/200\n",
      "77021/77021 [==============================] - 234s 3ms/step - loss: 0.0534 - acc: 0.9855\n",
      "Epoch 45/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.0473 - acc: 0.9864\n",
      "Epoch 46/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0518 - acc: 0.9855\n",
      "Epoch 47/200\n",
      "77021/77021 [==============================] - 234s 3ms/step - loss: 0.0490 - acc: 0.9864\n",
      "Epoch 48/200\n",
      "77021/77021 [==============================] - 234s 3ms/step - loss: 0.0506 - acc: 0.9858\n",
      "Epoch 49/200\n",
      "77021/77021 [==============================] - 233s 3ms/step - loss: 0.0487 - acc: 0.9865\n",
      "Epoch 50/200\n",
      "77021/77021 [==============================] - 249s 3ms/step - loss: 0.0444 - acc: 0.9868\n",
      "Epoch 51/200\n",
      "77021/77021 [==============================] - 235s 3ms/step - loss: 0.0490 - acc: 0.9854\n",
      "Epoch 52/200\n",
      "77021/77021 [==============================] - 238s 3ms/step - loss: 0.0464 - acc: 0.9869\n",
      "Epoch 53/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0509 - acc: 0.9861\n",
      "Epoch 54/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0478 - acc: 0.9865\n",
      "Epoch 55/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0481 - acc: 0.9867\n",
      "Epoch 56/200\n",
      "77021/77021 [==============================] - 243s 3ms/step - loss: 0.0482 - acc: 0.9864\n",
      "Epoch 57/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.0506 - acc: 0.9865\n",
      "Epoch 58/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.0487 - acc: 0.9866\n",
      "Epoch 59/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0497 - acc: 0.9865\n",
      "Epoch 60/200\n",
      "77021/77021 [==============================] - 242s 3ms/step - loss: 0.0481 - acc: 0.9870\n",
      "Epoch 61/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.0520 - acc: 0.9863\n",
      "Epoch 62/200\n",
      "77021/77021 [==============================] - 242s 3ms/step - loss: 0.0478 - acc: 0.9870\n",
      "Epoch 63/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0487 - acc: 0.9867\n",
      "Epoch 64/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0469 - acc: 0.9871\n",
      "Epoch 65/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.0486 - acc: 0.9871\n",
      "Epoch 66/200\n",
      "77021/77021 [==============================] - 238s 3ms/step - loss: 0.0469 - acc: 0.9870\n",
      "Epoch 67/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.0515 - acc: 0.9868\n",
      "Epoch 68/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.0483 - acc: 0.9873\n",
      "Epoch 69/200\n",
      "77021/77021 [==============================] - 238s 3ms/step - loss: 0.0486 - acc: 0.9872\n",
      "Epoch 70/200\n",
      "77021/77021 [==============================] - 240s 3ms/step - loss: 0.0500 - acc: 0.9870\n",
      "Epoch 71/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0523 - acc: 0.9861\n",
      "Epoch 72/200\n",
      "77021/77021 [==============================] - 239s 3ms/step - loss: 0.0504 - acc: 0.9861\n",
      "Epoch 73/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.0507 - acc: 0.9874\n",
      "Epoch 74/200\n",
      "77021/77021 [==============================] - 239s 3ms/step - loss: 0.0467 - acc: 0.9882\n",
      "Epoch 75/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.0496 - acc: 0.9871\n",
      "Epoch 76/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.0471 - acc: 0.9871 \n",
      "Epoch 77/200\n",
      "77021/77021 [==============================] - 238s 3ms/step - loss: 0.0535 - acc: 0.9868\n",
      "Epoch 78/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0505 - acc: 0.9870\n",
      "Epoch 79/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.0505 - acc: 0.9871\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77021/77021 [==============================] - 228s 3ms/step - loss: 0.0472 - acc: 0.9877\n",
      "Epoch 81/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0482 - acc: 0.9877\n",
      "Epoch 82/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0532 - acc: 0.9873\n",
      "Epoch 83/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0503 - acc: 0.9878\n",
      "Epoch 84/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0525 - acc: 0.9870\n",
      "Epoch 85/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0512 - acc: 0.9869 2s - \n",
      "Epoch 86/200\n",
      "77021/77021 [==============================] - 222s 3ms/step - loss: 0.0515 - acc: 0.9873\n",
      "Epoch 87/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0508 - acc: 0.9875\n",
      "Epoch 88/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0478 - acc: 0.9879\n",
      "Epoch 89/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.0486 - acc: 0.9879\n",
      "Epoch 90/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0510 - acc: 0.9879\n",
      "Epoch 91/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0516 - acc: 0.9870\n",
      "Epoch 92/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0518 - acc: 0.9875\n",
      "Epoch 93/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.0526 - acc: 0.9876\n",
      "Epoch 94/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0560 - acc: 0.9868\n",
      "Epoch 95/200\n",
      "77021/77021 [==============================] - 222s 3ms/step - loss: 0.0517 - acc: 0.9878\n",
      "Epoch 96/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0498 - acc: 0.9884\n",
      "Epoch 97/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0544 - acc: 0.9878\n",
      "Epoch 98/200\n",
      "77021/77021 [==============================] - 222s 3ms/step - loss: 0.0619 - acc: 0.9860\n",
      "Epoch 99/200\n",
      "77021/77021 [==============================] - 227s 3ms/step - loss: 0.0482 - acc: 0.9887\n",
      "Epoch 100/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0574 - acc: 0.9871\n",
      "Epoch 101/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0510 - acc: 0.9882\n",
      "Epoch 102/200\n",
      "77021/77021 [==============================] - 222s 3ms/step - loss: 0.0522 - acc: 0.9878\n",
      "Epoch 103/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0587 - acc: 0.9877 2s \n",
      "Epoch 104/200\n",
      "77021/77021 [==============================] - 227s 3ms/step - loss: 0.0533 - acc: 0.9879\n",
      "Epoch 105/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.0597 - acc: 0.9878\n",
      "Epoch 106/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0535 - acc: 0.9882\n",
      "Epoch 107/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0539 - acc: 0.9883\n",
      "Epoch 108/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.0560 - acc: 0.9875\n",
      "Epoch 109/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0573 - acc: 0.9874\n",
      "Epoch 110/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0540 - acc: 0.9881\n",
      "Epoch 111/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.0607 - acc: 0.9864\n",
      "Epoch 112/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.0571 - acc: 0.9874\n",
      "Epoch 113/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0717 - acc: 0.9855\n",
      "Epoch 114/200\n",
      "77021/77021 [==============================] - 222s 3ms/step - loss: 0.0566 - acc: 0.9876\n",
      "Epoch 115/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.0614 - acc: 0.9869\n",
      "Epoch 116/200\n",
      "77021/77021 [==============================] - 222s 3ms/step - loss: 0.0630 - acc: 0.9867\n",
      "Epoch 117/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.0571 - acc: 0.9871\n",
      "Epoch 118/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0599 - acc: 0.9870\n",
      "Epoch 119/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0630 - acc: 0.9863\n",
      "Epoch 120/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0613 - acc: 0.9869\n",
      "Epoch 121/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0626 - acc: 0.9869\n",
      "Epoch 122/200\n",
      "77021/77021 [==============================] - 225s 3ms/step - loss: 0.0608 - acc: 0.9874\n",
      "Epoch 123/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0647 - acc: 0.9875\n",
      "Epoch 124/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0682 - acc: 0.9861\n",
      "Epoch 125/200\n",
      "77021/77021 [==============================] - 227s 3ms/step - loss: 0.0681 - acc: 0.9864\n",
      "Epoch 126/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0599 - acc: 0.9874\n",
      "Epoch 127/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.0712 - acc: 0.9859\n",
      "Epoch 128/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0663 - acc: 0.9868\n",
      "Epoch 129/200\n",
      "77021/77021 [==============================] - 10221s 133ms/step - loss: 0.0658 - acc: 0.9873\n",
      "Epoch 130/200\n",
      "77021/77021 [==============================] - 160s 2ms/step - loss: 0.0661 - acc: 0.9874\n",
      "Epoch 131/200\n",
      "77021/77021 [==============================] - 165s 2ms/step - loss: 0.0757 - acc: 0.9860\n",
      "Epoch 132/200\n",
      "77021/77021 [==============================] - 180s 2ms/step - loss: 0.0735 - acc: 0.9861\n",
      "Epoch 133/200\n",
      "77021/77021 [==============================] - 200s 3ms/step - loss: 0.0669 - acc: 0.9866\n",
      "Epoch 134/200\n",
      "77021/77021 [==============================] - 210s 3ms/step - loss: 0.0694 - acc: 0.9869\n",
      "Epoch 135/200\n",
      "77021/77021 [==============================] - 215s 3ms/step - loss: 0.0748 - acc: 0.9862\n",
      "Epoch 136/200\n",
      "77021/77021 [==============================] - 220s 3ms/step - loss: 0.0791 - acc: 0.9861\n",
      "Epoch 137/200\n",
      "77021/77021 [==============================] - 221s 3ms/step - loss: 0.0788 - acc: 0.9861\n",
      "Epoch 138/200\n",
      "77021/77021 [==============================] - 222s 3ms/step - loss: 0.0795 - acc: 0.9863\n",
      "Epoch 139/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0889 - acc: 0.9849\n",
      "Epoch 140/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.0859 - acc: 0.9850 2\n",
      "Epoch 141/200\n",
      "77021/77021 [==============================] - 229s 3ms/step - loss: 0.0833 - acc: 0.9852\n",
      "Epoch 142/200\n",
      "77021/77021 [==============================] - 229s 3ms/step - loss: 0.0990 - acc: 0.9837\n",
      "Epoch 143/200\n",
      "77021/77021 [==============================] - 229s 3ms/step - loss: 0.0984 - acc: 0.9837\n",
      "Epoch 144/200\n",
      "77021/77021 [==============================] - 230s 3ms/step - loss: 0.0928 - acc: 0.9834\n",
      "Epoch 145/200\n",
      "77021/77021 [==============================] - 232s 3ms/step - loss: 0.1151 - acc: 0.9816\n",
      "Epoch 146/200\n",
      "77021/77021 [==============================] - 232s 3ms/step - loss: 0.0930 - acc: 0.9831\n",
      "Epoch 147/200\n",
      "77021/77021 [==============================] - 231s 3ms/step - loss: 0.1041 - acc: 0.9832\n",
      "Epoch 148/200\n",
      "77021/77021 [==============================] - 232s 3ms/step - loss: 0.1161 - acc: 0.9798\n",
      "Epoch 149/200\n",
      "77021/77021 [==============================] - 231s 3ms/step - loss: 0.1188 - acc: 0.9811\n",
      "Epoch 150/200\n",
      "77021/77021 [==============================] - 232s 3ms/step - loss: 0.1193 - acc: 0.9801 0s - loss: 0.1194 - acc: 0\n",
      "Epoch 151/200\n",
      "77021/77021 [==============================] - 230s 3ms/step - loss: 0.1221 - acc: 0.9821\n",
      "Epoch 152/200\n",
      "77021/77021 [==============================] - 230s 3ms/step - loss: 0.1223 - acc: 0.9819\n",
      "Epoch 153/200\n",
      "77021/77021 [==============================] - 232s 3ms/step - loss: 0.1110 - acc: 0.9823\n",
      "Epoch 154/200\n",
      "77021/77021 [==============================] - 230s 3ms/step - loss: 0.1262 - acc: 0.9804\n",
      "Epoch 155/200\n",
      "77021/77021 [==============================] - 213s 3ms/step - loss: 0.1328 - acc: 0.9807\n",
      "Epoch 156/200\n",
      "77021/77021 [==============================] - 209s 3ms/step - loss: 0.1407 - acc: 0.9784\n",
      "Epoch 157/200\n",
      "77021/77021 [==============================] - 204s 3ms/step - loss: 0.1404 - acc: 0.9786\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77021/77021 [==============================] - 207s 3ms/step - loss: 0.1349 - acc: 0.9800\n",
      "Epoch 159/200\n",
      "77021/77021 [==============================] - 208s 3ms/step - loss: 0.1431 - acc: 0.9767 1s - loss: 0.1433\n",
      "Epoch 160/200\n",
      "77021/77021 [==============================] - 207s 3ms/step - loss: 0.1568 - acc: 0.9758\n",
      "Epoch 161/200\n",
      "77021/77021 [==============================] - 223s 3ms/step - loss: 0.1471 - acc: 0.9802\n",
      "Epoch 162/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.1852 - acc: 0.9748\n",
      "Epoch 163/200\n",
      "77021/77021 [==============================] - 275s 4ms/step - loss: 0.1578 - acc: 0.9790\n",
      "Epoch 164/200\n",
      "77021/77021 [==============================] - 313s 4ms/step - loss: 0.1877 - acc: 0.9776\n",
      "Epoch 165/200\n",
      "77021/77021 [==============================] - 312s 4ms/step - loss: 0.1809 - acc: 0.9761\n",
      "Epoch 166/200\n",
      "77021/77021 [==============================] - 312s 4ms/step - loss: 0.1673 - acc: 0.9752\n",
      "Epoch 167/200\n",
      "77021/77021 [==============================] - 313s 4ms/step - loss: 0.1942 - acc: 0.9731\n",
      "Epoch 168/200\n",
      "77021/77021 [==============================] - 241s 3ms/step - loss: 0.1988 - acc: 0.9723\n",
      "Epoch 169/200\n",
      "77021/77021 [==============================] - 254s 3ms/step - loss: 0.1722 - acc: 0.9763\n",
      "Epoch 170/200\n",
      "77021/77021 [==============================] - 224s 3ms/step - loss: 0.1622 - acc: 0.9780\n",
      "Epoch 171/200\n",
      "77021/77021 [==============================] - 263s 3ms/step - loss: 0.1861 - acc: 0.9749\n",
      "Epoch 172/200\n",
      "77021/77021 [==============================] - 268s 3ms/step - loss: 0.1734 - acc: 0.9773\n",
      "Epoch 173/200\n",
      "77021/77021 [==============================] - 260s 3ms/step - loss: 0.1994 - acc: 0.9751 1s - loss: 0.1988 \n",
      "Epoch 174/200\n",
      "77021/77021 [==============================] - 237s 3ms/step - loss: 0.2244 - acc: 0.9688\n",
      "Epoch 175/200\n",
      "77021/77021 [==============================] - 273s 4ms/step - loss: 0.2157 - acc: 0.9694\n",
      "Epoch 176/200\n",
      "77021/77021 [==============================] - 274s 4ms/step - loss: 0.2084 - acc: 0.9648\n",
      "Epoch 177/200\n",
      "77021/77021 [==============================] - 257s 3ms/step - loss: 0.2487 - acc: 0.9637\n",
      "Epoch 178/200\n",
      "77021/77021 [==============================] - 253s 3ms/step - loss: 0.2295 - acc: 0.9692\n",
      "Epoch 179/200\n",
      "77021/77021 [==============================] - 264s 3ms/step - loss: 0.2393 - acc: 0.9676\n",
      "Epoch 180/200\n",
      "77021/77021 [==============================] - 257s 3ms/step - loss: 0.2584 - acc: 0.9660 4s - loss: 0.2593 - acc: - ET\n",
      "Epoch 181/200\n",
      "77021/77021 [==============================] - 251s 3ms/step - loss: 0.2264 - acc: 0.9661 0s - loss: 0.2265 - acc: 0.96\n",
      "Epoch 182/200\n",
      "77021/77021 [==============================] - 252s 3ms/step - loss: 0.2724 - acc: 0.9662 4s - loss: 0.2716 - acc: 0\n",
      "Epoch 183/200\n",
      "77021/77021 [==============================] - 251s 3ms/step - loss: 0.2452 - acc: 0.9659\n",
      "Epoch 184/200\n",
      "77021/77021 [==============================] - 261s 3ms/step - loss: 0.2497 - acc: 0.9624\n",
      "Epoch 185/200\n",
      "77021/77021 [==============================] - 251s 3ms/step - loss: 0.2742 - acc: 0.9629\n",
      "Epoch 186/200\n",
      "77021/77021 [==============================] - 251s 3ms/step - loss: 0.3446 - acc: 0.9613\n",
      "Epoch 187/200\n",
      "77021/77021 [==============================] - 275s 4ms/step - loss: 0.2544 - acc: 0.9665\n",
      "Epoch 188/200\n",
      "77021/77021 [==============================] - 280s 4ms/step - loss: 0.3032 - acc: 0.9585\n",
      "Epoch 189/200\n",
      "77021/77021 [==============================] - 236s 3ms/step - loss: 0.2699 - acc: 0.9575\n",
      "Epoch 190/200\n",
      "77021/77021 [==============================] - 242s 3ms/step - loss: 0.2716 - acc: 0.9593 2s - loss:\n",
      "Epoch 191/200\n",
      "77021/77021 [==============================] - 229s 3ms/step - loss: 0.2827 - acc: 0.9650\n",
      "Epoch 192/200\n",
      "77021/77021 [==============================] - 226s 3ms/step - loss: 0.3061 - acc: 0.9552\n",
      "Epoch 193/200\n",
      "77021/77021 [==============================] - 277s 4ms/step - loss: 0.3055 - acc: 0.9546\n",
      "Epoch 194/200\n",
      "77021/77021 [==============================] - 288s 4ms/step - loss: 0.2748 - acc: 0.9637\n",
      "Epoch 195/200\n",
      "77021/77021 [==============================] - 265s 3ms/step - loss: 0.3486 - acc: 0.9487\n",
      "Epoch 196/200\n",
      "77021/77021 [==============================] - 275s 4ms/step - loss: 0.3828 - acc: 0.9459\n",
      "Epoch 197/200\n",
      "77021/77021 [==============================] - 282s 4ms/step - loss: 0.3365 - acc: 0.9543\n",
      "Epoch 198/200\n",
      "77021/77021 [==============================] - 302s 4ms/step - loss: 0.3762 - acc: 0.9419\n",
      "Epoch 199/200\n",
      "77021/77021 [==============================] - 282s 4ms/step - loss: 0.3722 - acc: 0.9403\n",
      "Epoch 200/200\n",
      "77021/77021 [==============================] - 267s 3ms/step - loss: 0.3821 - acc: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x234c0e57a58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(l), cat, epochs=200,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
